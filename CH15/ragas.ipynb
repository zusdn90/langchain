{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성 테스트 데이터셋 생성\n",
    "\n",
    "왜 합성 테스트 데이터(Synthetic Test Dataset) 인가?\n",
    "\n",
    "RAG(검색 증강 생성) 증강 파이프라인의 성능을 평가하는 것은 매우 중요합니다.\n",
    "\n",
    "그러나 문서에서 수백 개의 QA(질문-문맥-응답) 샘플을 수동으로 생성하는 것은 시간과 노동력이 많이 소요될 수 있습니다. 또한 사람이 만든 질문은 철저한 평가에 필요한 복잡성 수준에 도달하기 어려워 궁극적으로 평가의 품질에 영향을 미칠 수 있습니다.\n",
    "\n",
    "합성 데이터 생성을 사용하면 데이터 집계 프로세스에서 개발자의 시간을 90% 까지 줄일 수 있습니다.\n",
    "\n",
    "RAGAS: https://docs.ragas.io/en/latest/concepts/testset_generation.html\n",
    "\n",
    "**참고**\n",
    "\n",
    "(2024.10.08 현재) ragas 패키지는 0.2.16 버전의 langchain 패키지와 호환됩니다.\n",
    "\n",
    "따라서 버전을 0.2.16 버전으로 설치해야 합니다. (현재, 0.3.x 버전으로 우리가 사용하는 버전이 더 상위 버전입니다)\n",
    "\n",
    "아래의 주석을 해제 후 진행해 주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-community 0.3.20 requires langchain<1.0.0,>=0.3.21, but you have langchain 0.2.16 which is incompatible.\n",
      "langchain-community 0.3.20 requires langchain-core<1.0.0,>=0.3.45, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-ollama 0.3.0 requires langchain-core<1.0.0,>=0.3.47, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-anthropic 0.3.10 requires langchain-core<1.0.0,>=0.3.45, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-openai 0.3.11 requires langchain-core<1.0.0,>=0.3.49, but you have langchain-core 0.2.43 which is incompatible.\n",
      "langchain-mcp-adapters 0.0.5 requires langchain-core<0.4,>=0.3.36, but you have langchain-core 0.2.43 which is incompatible.\n",
      "open-webui 0.5.20 requires aiohttp==3.11.11, but you have aiohttp 3.11.14 which is incompatible.\n",
      "open-webui 0.5.20 requires googleapis-common-protos==1.63.2, but you have googleapis-common-protos 1.69.2 which is incompatible.\n",
      "open-webui 0.5.20 requires langchain==0.3.19, but you have langchain 0.2.16 which is incompatible.\n",
      "open-webui 0.5.20 requires langchain-community==0.3.18, but you have langchain-community 0.3.20 which is incompatible.\n",
      "open-webui 0.5.20 requires pydantic==2.10.6, but you have pydantic 2.11.0 which is incompatible.\n",
      "open-webui 0.5.20 requires sqlalchemy==2.0.38, but you have sqlalchemy 2.0.40 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-experimental 0.3.4 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.2.19 which is incompatible.\n",
      "langchain-experimental 0.3.4 requires langchain-core<0.4.0,>=0.3.28, but you have langchain-core 0.2.43 which is incompatible.\n",
      "open-webui 0.5.20 requires aiohttp==3.11.11, but you have aiohttp 3.11.14 which is incompatible.\n",
      "open-webui 0.5.20 requires googleapis-common-protos==1.63.2, but you have googleapis-common-protos 1.69.2 which is incompatible.\n",
      "open-webui 0.5.20 requires langchain==0.3.19, but you have langchain 0.2.17 which is incompatible.\n",
      "open-webui 0.5.20 requires langchain-community==0.3.18, but you have langchain-community 0.2.19 which is incompatible.\n",
      "open-webui 0.5.20 requires pydantic==2.10.6, but you have pydantic 2.11.0 which is incompatible.\n",
      "open-webui 0.5.20 requires sqlalchemy==2.0.38, but you have sqlalchemy 2.0.40 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain==0.2.16\n",
    "!pip install -q ragas==0.1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Version: 0.2.17\n",
      "Ragas Version: 0.1.19\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import ragas\n",
    "\n",
    "print(f\"LangChain Version: {langchain.__version__}\")\n",
    "print(f\"Ragas Version: {ragas.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH16-Evaluations\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH16-Evaluations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# 문서 로더 생성\n",
    "loader = PDFPlumberLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "\n",
    "# 목차, 끝 페이지 제외\n",
    "docs = docs[3:-1]\n",
    "\n",
    "# 문서의 페이지수\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata 설정(filename 이 존재해야 함)\n",
    "for doc in docs:\n",
    "    doc.metadata[\"filename\"] = doc.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, conditional\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.extractor import KeyphraseExtractor\n",
    "from ragas.testset.docstore import InMemoryDocumentStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 데이터셋 생성기\n",
    "generator_llm = ChatOllama(model=\"gemma3:1b\")\n",
    "# 데이터셋 비평기\n",
    "critic_llm = ChatOllama(model=\"gemma3:1b\")\n",
    "# 문서 임베딩\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DocumentStore를 초기화합니다. 사용자 정의 LLM과 임베딩을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할기를 설정합니다.\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# LangChain의 ChatOllama 모델을 LangchainLLMWrapper로 감싸 Ragas와 호환되게 만듭니다.\n",
    "langchain_llm = LangchainLLMWrapper(ChatOllama(model=\"gemma3:1b\"))\n",
    "\n",
    "# 주요 구문 추출기를 초기화합니다. 위에서 정의한 LLM을 사용합니다.\n",
    "keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)\n",
    "\n",
    "# ragas_embeddings 생성\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "# InMemoryDocumentStore를 초기화합니다.\n",
    "# 이는 문서를 메모리에 저장하고 관리하는 저장소입니다.\n",
    "docstore = InMemoryDocumentStore(\n",
    "    splitter=splitter,\n",
    "    embeddings=ragas_embeddings,\n",
    "    extractor=keyphrase_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TestSet 을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    ragas_embeddings,\n",
    "    docstore=docstore,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문의 유형별 분포\n",
    "\n",
    "- simple: 간단한 질문\n",
    "- reasoning: 추론이 필요한 질문\n",
    "- multi_context: 여러 맥락을 고려해야 하는 질문\n",
    "- conditional: 조건부 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 유형별 분포 결정\n",
    "# simple: 간단한 질문, reasoning: 추론이 필요한 질문, multi_context: 여러 맥락을 고려해야 하는 질문, conditional: 조건부 질문\n",
    "distributions = {simple: 0.4, reasoning: 0.2, multi_context: 0.2, conditional: 0.2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- documents: 문서 데이터\n",
    "- test_size: 생성할 질문의 수\n",
    "- distributions: 질문 유형별 분포\n",
    "- with_debugging_logs: 디버깅 로그 출력 여부\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fda111111b84b87b1f06522511e7dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 테스트셋 생성\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# docs: 문서 데이터, 10: 생성할 질문의 수, distributions: 질문 유형별 분포, with_debugging_logs: 디버깅 로그 출력 여부\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m testset = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_debugging_logs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/ragas/testset/generator.py:206\u001b[39m, in \u001b[36mTestsetGenerator.generate_with_langchain_docs\u001b[39m\u001b[34m(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\u001b[39m\n\u001b[32m    204\u001b[39m distributions = distributions \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# chunk documents and add to docstore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdocstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mDocument\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_langchain_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate(\n\u001b[32m    211\u001b[39m     test_size=test_size,\n\u001b[32m    212\u001b[39m     distributions=distributions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    216\u001b[39m     run_config=run_config,\n\u001b[32m    217\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/ragas/testset/docstore.py:214\u001b[39m, in \u001b[36mInMemoryDocumentStore.add_documents\u001b[39m\u001b[34m(self, docs, show_progress)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# split documents with self.splitter into smaller nodes\u001b[39;00m\n\u001b[32m    210\u001b[39m nodes = [\n\u001b[32m    211\u001b[39m     Node.from_langchain_document(d)\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.splitter.transform_documents(docs)\n\u001b[32m    213\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/ragas/testset/docstore.py:251\u001b[39m, in \u001b[36mInMemoryDocumentStore.add_nodes\u001b[39m\u001b[34m(self, nodes, show_progress)\u001b[39m\n\u001b[32m    244\u001b[39m         executor.submit(\n\u001b[32m    245\u001b[39m             \u001b[38;5;28mself\u001b[39m.extractor.extract,\n\u001b[32m    246\u001b[39m             n,\n\u001b[32m    247\u001b[39m             name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mkeyphrase-extraction[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    248\u001b[39m         )\n\u001b[32m    249\u001b[39m         result_idx += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/ragas/executor.py:118\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    114\u001b[39m         results.append(r)\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_aresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/selectors.py:566\u001b[39m, in \u001b[36mKqueueSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    564\u001b[39m ready = []\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     kev_list = \u001b[38;5;28mself\u001b[39m._selector.control(\u001b[38;5;28;01mNone\u001b[39;00m, max_ev, timeout)\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 테스트셋 생성\n",
    "# docs: 문서 데이터, 10: 생성할 질문의 수, distributions: 질문 유형별 분포, with_debugging_logs: 디버깅 로그 출력 여부\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents=docs, test_size=10, distributions=distributions, with_debugging_logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 생성된 테스트셋을 pandas DataFrame으로 변환\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_df = \u001b[43mtestset\u001b[49m.to_pandas()\n\u001b[32m      3\u001b[39m test_df\n",
      "\u001b[31mNameError\u001b[39m: name 'testset' is not defined"
     ]
    }
   ],
   "source": [
    "# 생성된 테스트셋을 pandas DataFrame으로 변환\n",
    "test_df = testset.to_pandas()\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# DataFrame의 상위 5개 행 출력\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtest_df\u001b[49m.head()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# DataFrame을 CSV 파일로 저장\u001b[39;00m\n\u001b[32m      5\u001b[39m test_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/ragas_synthetic_dataset.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "# DataFrame의 상위 5개 행 출력\n",
    "test_df.head()\n",
    "\n",
    "# DataFrame을 CSV 파일로 저장\n",
    "test_df.to_csv(\"data/ragas_synthetic_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

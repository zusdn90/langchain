{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "hhw_langchain_toy_project\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"hhw_langchain_toy_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4yvbq7s16359fdr947szsx5h0000gn/T/ipykernel_43503/1215388266.py:5: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"gemma3:1b\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Ollama ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "llm = ChatOllama(model=\"gemma3:1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°©ë²• 1. from_template() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ PromptTemplate ê°ì²´ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template ì •ì˜. {country}ëŠ” ë³€ìˆ˜ë¡œ, ì´í›„ì— ê°’ì´ ë“¤ì–´ê°ˆ ìë¦¬ë¥¼ ì˜ë¯¸\n",
    "template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# from_template ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ PromptTemplate ê°ì²´ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt ìƒì„±. format ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ ë³€ìˆ˜ì— ê°’ì„ ë„£ì–´ì¤Œ\n",
    "prompt = prompt.format(country=\"ëŒ€í•œë¯¼êµ­\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template ì •ì˜\n",
    "template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# from_template ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ PromptTemplate ê°ì²´ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# chain ìƒì„±\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# country ë³€ìˆ˜ì— ì…ë ¥ëœ ê°’ì´ ìë™ìœ¼ë¡œ ì¹˜í™˜ë˜ì–´ ìˆ˜í–‰ë¨\n",
    "chain.invoke(\"ëŒ€í•œë¯¼êµ­\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°©ë²• 2. PromptTemplate ê°ì²´ ìƒì„±ê³¼ ë™ì‹œì— prompt ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶”ê°€ ìœ íš¨ì„± ê²€ì‚¬ë¥¼ ìœ„í•´ input_variables ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì„¸ìš”.\n",
    "\n",
    "ì´ëŸ¬í•œ ë³€ìˆ˜ëŠ” ì¸ìŠ¤í„´ìŠ¤í™” ì¤‘ì— í…œí”Œë¦¿ ë¬¸ìì—´ì— ìˆëŠ” ë³€ìˆ˜ì™€ ë¹„êµí•˜ì—¬ ë¶ˆì¼ì¹˜í•˜ëŠ” ê²½ìš° ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template ì •ì˜\n",
    "template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# PromptTemplate ê°ì²´ë¥¼ í™œìš©í•˜ì—¬ prompt_template ìƒì„±\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt ìƒì„±\n",
    "prompt.format(country=\"ëŒ€í•œë¯¼êµ­\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country1'], input_types={}, partial_variables={'country2': 'ë¯¸êµ­'}, template='{country1}ê³¼ {country2}ì˜ ìˆ˜ë„ëŠ” ê°ê° ì–´ë””ì¸ê°€ìš”?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template ì •ì˜\n",
    "template = \"{country1}ê³¼ {country2}ì˜ ìˆ˜ë„ëŠ” ê°ê° ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# PromptTemplate ê°ì²´ë¥¼ í™œìš©í•˜ì—¬ prompt_template ìƒì„±\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country1\"],\n",
    "    partial_variables={\n",
    "        \"country2\": \"ë¯¸êµ­\"  # dictionary í˜•íƒœë¡œ partial_variablesë¥¼ ì „ë‹¬\n",
    "    },\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ê³¼ ë¯¸êµ­ì˜ ìˆ˜ë„ëŠ” ê°ê° ì–´ë””ì¸ê°€ìš”?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country1=\"ëŒ€í•œë¯¼êµ­\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country1'], input_types={}, partial_variables={'country2': 'ìºë‚˜ë‹¤'}, template='{country1}ê³¼ {country2}ì˜ ìˆ˜ë„ëŠ” ê°ê° ì–´ë””ì¸ê°€ìš”?')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial = prompt.partial(country2=\"ìºë‚˜ë‹¤\")\n",
    "prompt_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ê³¼ ìºë‚˜ë‹¤ì˜ ìˆ˜ë„ëŠ” ê°ê° ì–´ë””ì¸ê°€ìš”?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial.format(country1=\"ëŒ€í•œë¯¼êµ­\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_partial | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*   **ëŒ€í•œë¯¼êµ­:** ì„œìš¸\\n*   **ìºë‚˜ë‹¤:** í† ë¡ í† '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"ëŒ€í•œë¯¼êµ­\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*   **ëŒ€í•œë¯¼êµ­:** ì„œìš¸\\n*   **í˜¸ì£¼:**ìº”ë²„ë¼'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country1\": \"ëŒ€í•œë¯¼êµ­\", \"country2\": \"í˜¸ì£¼\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'March 23'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ì¶œë ¥\n",
    "datetime.now().strftime(\"%B %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚ ì§œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ ì •ì˜\n",
    "def get_today():\n",
    "    return datetime.now().strftime(\"%B %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"ì˜¤ëŠ˜ì˜ ë‚ ì§œëŠ” {today} ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì´ ìƒì¼ì¸ ìœ ëª…ì¸ {n}ëª…ì„ ë‚˜ì—´í•´ ì£¼ì„¸ìš”. ìƒë…„ì›”ì¼ì„ í‘œê¸°í•´ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[\"n\"],\n",
    "    partial_variables={\n",
    "        \"today\": get_today  # dictionary í˜•íƒœë¡œ partial_variablesë¥¼ ì „ë‹¬\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì˜¤ëŠ˜ì˜ ë‚ ì§œëŠ” March 23 ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì´ ìƒì¼ì¸ ìœ ëª…ì¸ 3ëª…ì„ ë‚˜ì—´í•´ ì£¼ì„¸ìš”. ìƒë…„ì›”ì¼ì„ í‘œê¸°í•´ì£¼ì„¸ìš”.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt ìƒì„±\n",
    "prompt.format(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜(2024ë…„ 3ì›” 23ì¼) ìƒì¼ì¸ ìœ ëª…ì¸ 3ëª…ì„ ë‚˜ì—´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "| ì´ë¦„           | ìƒë…„ì›”ì¼       |\n",
      "| -------------- | ------------- |\n",
      "| ì•¤ë“œë¥˜ ë• í˜• (Andrew Yang) | 1971ë…„ 12ì›” 17ì¼ |\n",
      "| ì—˜ë¦¬ìë² ìŠ¤ ë²¤ìŠ¨ (Elizabeth Beneson) | 1968ë…„ 7ì›” 26ì¼ |\n",
      "| ì­ ì­ìŠ¨ (Jack Jackson) | 1958ë…„ 1ì›” 25ì¼ |\n",
      "\n",
      "ì´ ì™¸ì—ë„ ë§ì€ ìœ ëª…ì¸ë“¤ì´ ìƒì¼ì„ ë§ì´í•˜ê³  ìˆìŠµë‹ˆë‹¤. í˜¹ì‹œ íŠ¹ì • ë¶„ì•¼ì˜ ìœ ëª…ì¸ì— ëŒ€í•´ ë” ìì„¸í•œ ì •ë³´ë¥¼ ì›í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# chain ì„ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "print(chain.invoke(3).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜(2024ë…„ 1ì›” 2ì¼) ìƒì¼ì¸ ìœ ëª…ì¸ 3ëª…ì„ ë‚˜ì—´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **ê¹€í˜œë¦¬** (1970ë…„ 1ì›” 2ì¼) - ë°°ìš°\n",
      "2.  **ì´ì •ì¬** (1977ë…„ 1ì›” 2ì¼) - ë°°ìš°, ê°ë…\n",
      "3.  **ê¹€ì² ìˆ˜** (1968ë…„ 1ì›” 2ì¼) - ë°°ìš°, ê°€ìˆ˜\n",
      "\n",
      "í˜¹ì‹œ ë‹¤ë¥¸ íŠ¹ì • ë¶„ì•¼ì˜ ìœ ëª…ì¸ì´ë‚˜ íŠ¹ì • ì—°ë ¹ëŒ€ì˜ ìœ ëª…ì¸ì„ ì›í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# chain ì„ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "print(chain.invoke({\"today\": \"Jan 02\", \"n\": 3}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "íŒŒì¼ë¡œë¶€í„° template ì½ì–´ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['fruit'], input_types={}, partial_variables={}, template='{fruit}ì˜ ìƒ‰ê¹”ì´ ë­ì•¼?')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"prompts/fruit_color.yaml\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì‚¬ê³¼ì˜ ìƒ‰ê¹”ì´ ë­ì•¼?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(fruit=\"ì‚¬ê³¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì— ëŒ€í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”.\n",
      "ìˆ˜ë„ì˜ íŠ¹ì§•ì„ ë‹¤ìŒì˜ ì–‘ì‹ì— ë§ê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\n",
      "300ì ë‚´ì™¸ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
      "í•œê¸€ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
      "----\n",
      "[ì–‘ì‹]\n",
      "1. ë©´ì \n",
      "2. ì¸êµ¬\n",
      "3. ì—­ì‚¬ì  ì¥ì†Œ\n",
      "4. íŠ¹ì‚°í’ˆ\n",
      "\n",
      "#Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt2 = load_prompt(\"prompts/capital.yaml\")\n",
    "print(prompt2.format(country=\"ëŒ€í•œë¯¼êµ­\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatPromptTemplate ì€ ëŒ€í™”ëª©ë¡ì„ í”„ë¡¬í”„íŠ¸ë¡œ ì£¼ì…í•˜ê³ ì í•  ë•Œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë©”ì‹œì§€ëŠ” íŠœí”Œ(tuple) í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•˜ë©°, (role, message) ë¡œ êµ¬ì„±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format(country=\"ëŒ€í•œë¯¼êµ­\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ í˜„ìš° ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ë°˜ê°€ì›Œìš”!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # role, message\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ {name} ì…ë‹ˆë‹¤.\"),\n",
    "        (\"human\", \"ë°˜ê°€ì›Œìš”!\"),\n",
    "        (\"ai\", \"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ì±— message ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"í˜„ìš°\", user_input=\"ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\"\n",
    ")\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì €ëŠ” í˜„ìš°ì…ë‹ˆë‹¤. ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤! ğŸ˜Š'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì €ëŠ” Hyunwooì…ë‹ˆë‹¤. ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤! ğŸ˜Š'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"name\": \"Hyunwoo\", \"user_input\": \"ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MessagePlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë˜í•œ LangChainì€ í¬ë§·í•˜ëŠ” ë™ì•ˆ ë Œë”ë§í•  ë©”ì‹œì§€ë¥¼ ì™„ì „íˆ ì œì–´í•  ìˆ˜ ìˆëŠ” MessagePlaceholder ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ë©”ì‹œì§€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì–´ë–¤ ì—­í• ì„ ì‚¬ìš©í•´ì•¼ í• ì§€ í™•ì‹¤í•˜ì§€ ì•Šê±°ë‚˜ ì„œì‹ ì§€ì • ì¤‘ì— ë©”ì‹œì§€ ëª©ë¡ì„ ì‚½ì…í•˜ë ¤ëŠ” ê²½ìš° ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x107875260>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ìš” í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.'), additional_kwargs={}), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], input_types={}, partial_variables={}, template='ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ {word_count} ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ìš” í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ {word_count} ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\"),\n",
    "    ]\n",
    ")\n",
    "chat_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ìš” í‚¤ì›Œë“œë¡œ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "Human: ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì˜¤ëŠ˜ ìƒˆë¡œ ì…ì‚¬í•œ í˜„ìš° ì…ë‹ˆë‹¤. ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤.\n",
      "AI: ë°˜ê°€ì›Œìš”! ì•ìœ¼ë¡œ ì˜ ë¶€íƒ ë“œë¦½ë‹ˆë‹¤.\n",
      "Human: ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ 5 ë‹¨ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=5,\n",
    "    conversation=[\n",
    "        (\"human\", \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì˜¤ëŠ˜ ìƒˆë¡œ ì…ì‚¬í•œ í˜„ìš° ì…ë‹ˆë‹¤. ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤.\"),\n",
    "        (\"ai\", \"ë°˜ê°€ì›Œìš”! ì•ìœ¼ë¡œ ì˜ ë¶€íƒ ë“œë¦½ë‹ˆë‹¤.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(formatted_chat_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain ìƒì„±\n",
    "chain = chat_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*   **ì…ì‚¬, í˜„ìš°, ë§Œë‚˜ê¸°**'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain ì‹¤í–‰ ë° ê²°ê³¼í™•ì¸\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"word_count\": 5,\n",
    "        \"conversation\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì˜¤ëŠ˜ ìƒˆë¡œ ì…ì‚¬í•œ í˜„ìš° ì…ë‹ˆë‹¤. ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤.\",\n",
    "            ),\n",
    "            (\"ai\", \"ë°˜ê°€ì›Œìš”! ì•ìœ¼ë¡œ ì˜ ë¶€íƒ ë“œë¦½ë‹ˆë‹¤.\"),\n",
    "        ],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ ë©”ëª¨ë¦¬ëŠ” ë©”ì‹œì§€ë¥¼ ì €ì¥í•œ ë‹¤ìŒ ë³€ìˆ˜ì— ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € ë¬¸ìì—´ë¡œ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4yvbq7s16359fdr947szsx5h0000gn/T/ipykernel_5553/2227097840.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\\nAI: ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'history' í‚¤ì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: dictionary(key: \"human\" or \"ai\", value: ì§ˆë¬¸)\n",
    "# outputs: dictionary(key: \"ai\" or \"human\", value: ë‹µë³€)\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ê°œì˜ ëŒ€í™”ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ì€ ì´ì œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë³¸ì¸ ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì›í•˜ì‹œëŠ” ê³„ì¢Œ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆê¸ˆ ì¢…ë¥˜, í†µí™” ì¢…ë¥˜ ë“±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\n",
      "Human: ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "AI: ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "Human: ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\n",
      "AI: ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
      "Human: ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ì€ ì´ì œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n",
      "AI: ë³¸ì¸ ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì›í•˜ì‹œëŠ” ê³„ì¢Œ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆê¸ˆ ì¢…ë¥˜, í†µí™” ì¢…ë¥˜ ë“±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# historyì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ê°€ë¡œ 2ê°œì˜ ëŒ€í™”ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì •ë³´ë¥¼ ëª¨ë‘ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì…ë ¥í•´ ì£¼ì‹  ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ ì ˆì°¨ê°€ ê±°ì˜ ëë‚¬ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ìš© ì•½ê´€ì— ë™ì˜í•´ ì£¼ì‹œê³ , ê³„ì¢Œ ê°œì„¤ì„ ìµœì¢… í™•ì¸í•´ ì£¼ì„¸ìš”.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ëª¨ë“  ì ˆì°¨ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œê°€ ê°œì„¤ëœ ê±´ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë„¤, ê³„ì¢Œ ê°œì„¤ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ê³„ì¢Œ ë²ˆí˜¸ì™€ ê´€ë ¨ ì •ë³´ëŠ” ë“±ë¡í•˜ì‹  ì´ë©”ì¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤!\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\n",
      "Human: ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "AI: ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "Human: ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\n",
      "AI: ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
      "Human: ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ì€ ì´ì œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n",
      "AI: ë³¸ì¸ ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì›í•˜ì‹œëŠ” ê³„ì¢Œ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆê¸ˆ ì¢…ë¥˜, í†µí™” ì¢…ë¥˜ ë“±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "Human: ì •ë³´ë¥¼ ëª¨ë‘ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "AI: ì…ë ¥í•´ ì£¼ì‹  ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ ì ˆì°¨ê°€ ê±°ì˜ ëë‚¬ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ìš© ì•½ê´€ì— ë™ì˜í•´ ì£¼ì‹œê³ , ê³„ì¢Œ ê°œì„¤ì„ ìµœì¢… í™•ì¸í•´ ì£¼ì„¸ìš”.\n",
      "Human: ëª¨ë“  ì ˆì°¨ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œê°€ ê°œì„¤ëœ ê±´ê°€ìš”?\n",
      "AI: ë„¤, ê³„ì¢Œ ê°œì„¤ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ê³„ì¢Œ ë²ˆí˜¸ì™€ ê´€ë ¨ ì •ë³´ëŠ” ë“±ë¡í•˜ì‹  ì´ë©”ì¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# historyì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# historyì— ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain ì— ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "hhw_langchain_toy_project\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"hhw_langchain_toy_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4yvbq7s16359fdr947szsx5h0000gn/T/ipykernel_5553/2490649376.py:5: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"gemma3:1b\")\n",
      "/var/folders/5d/4yvbq7s16359fdr947szsx5h0000gn/T/ipykernel_5553/2490649376.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Ollama ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "llm = ChatOllama(model=\"gemma3:1b\")\n",
    "\n",
    "# ConversationChainì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "conversation = ConversationChain(\n",
    "    # ConversationBufferMemoryë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë‹ˆ, ì•„ì£¼ ì¢‹ì€ ìƒê°ì…ë‹ˆë‹¤! ğŸ˜Š  ì €ëŠ” í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ëŠ” AIì´ê¸° ë•Œë¬¸ì—, í•œêµ­ì–´ë¡œ ë‹µë³€ì„ ë“œë¦¬ë„ë¡ ì„¤ì •í–ˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ëŠ” ê³¼ì •ì€ í¬ê²Œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **ì€í–‰ ì„ íƒ:** ë¨¼ì € ì–´ë–¤ ì€í–‰ì„ ì´ìš©í• ì§€ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.  ê° ì€í–‰ë§ˆë‹¤ ì„œë¹„ìŠ¤ë‚˜ ìˆ˜ìˆ˜ë£Œê°€ ë‹¤ë¥´ë‹ˆ, ë³¸ì¸ì˜ ìƒí™©ì— ë§ëŠ” ê³³ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.  ì˜ˆë¥¼ ë“¤ì–´,  'ì‹ í•œì€í–‰', 'KBêµ­ë¦½ì€í–‰', 'í•˜ë‚˜ì€í–‰' ë“± ë‹¤ì–‘í•œ ì€í–‰ì´ ìˆìŠµë‹ˆë‹¤.  ê° ì€í–‰ì˜ íŠ¹ì§•ê³¼ ë¹„êµë¥¼ í•´ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ê² ë„¤ìš”.\n",
      "\n",
      "2.  **ì˜¨ë¼ì¸ ê³„ì¢Œ ê°œì„¤ ì‹ ì²­:** ê° ì€í–‰ì˜ ì›¹ì‚¬ì´íŠ¸ë‚˜ ì•±ì—ì„œ ì˜¨ë¼ì¸ ê³„ì¢Œ ê°œì„¤ ì‹ ì²­ì„ ì§„í–‰í•©ë‹ˆë‹¤.  ì‹ ì²­ ì‹œì—ëŠ” ë³¸ì¸ì˜ ì‹ ë¶„ì¦ ì‚¬ë³¸, ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸, ê·¸ë¦¬ê³  ê³„ì¢Œ ê°œì„¤ ëª©ì ì„ ì¦ëª…í•  ìˆ˜ ìˆëŠ” ì„œë¥˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3.  **ê³„ì¢Œ ì¢…ë¥˜ ì„ íƒ:**  ì–´ë–¤ ì¢…ë¥˜ì˜ ê³„ì¢Œë¥¼ ê°œì„¤í• ì§€ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.  ì˜ˆë¥¼ ë“¤ì–´,  'ì¼ë°˜ ê³„ì¢Œ', 'ìë™ ì´ì²´ ê³„ì¢Œ', 'ëŒ€ì¶œ ê³„ì¢Œ' ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤.  ê° ê³„ì¢Œì˜ íŠ¹ì§•ê³¼ ì‚¬ìš© ëª©ì ì„ ê³ ë ¤í•˜ì—¬ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "4.  **ê³„ì¢Œ ì •ë³´ ì…ë ¥:**  ê³„ì¢Œ ì¢…ë¥˜ì— ë”°ë¼ í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.  ì˜ˆë¥¼ ë“¤ì–´,  ê³„ì¢Œë²ˆí˜¸, ì˜ˆê¸ˆì, ê³„ì¢Œëª…, ê·¸ë¦¬ê³  ê³„ì¢Œ ì¢…ë¥˜ë¥¼ ì •í™•í•˜ê²Œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "5.  **ê³„ì¢Œ ê°œì„¤ ì‹ ì²­ì„œ ì‘ì„±:**  ê³„ì¢Œ ê°œì„¤ ì‹ ì²­ì„œì— í•„ìš”í•œ ì •ë³´ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.  ê³„ì¢Œ ê°œì„¤ ëª©ì ì„ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "6.  **ê³„ì¢Œ í™•ì¸ ë° ìŠ¹ì¸:**  ì€í–‰ì—ì„œ ì‹ ì²­í•œ ê³„ì¢Œ ê°œì„¤ ì‹ ì²­ì„œë¥¼ í™•ì¸í•˜ê³  ìŠ¹ì¸ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.  ìŠ¹ì¸ ê²°ê³¼ëŠ” ë³´í†µ ì´ë©”ì¼ì´ë‚˜ ì•±ì„ í†µí•´ ì•ˆë‚´ë©ë‹ˆë‹¤.\n",
      "\n",
      "7.  **ê³„ì¢Œ ê°œì„¤ ì™„ë£Œ:**  ì€í–‰ì—ì„œ ê³„ì¢Œ ê°œì„¤ì„ ì™„ë£Œí•˜ë©´, ê³„ì¢Œ ë²ˆí˜¸ì™€ ì˜ˆê¸ˆì ì •ë³´ë¥¼ í™•ì¸í•˜ì—¬ ê³„ì¢Œê°€ ê°œì„¤ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ì¶”ê°€ì ìœ¼ë¡œ, í˜¹ì‹œ ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?**\n",
      "\n",
      "*   **ì–´ë–¤ ì€í–‰ì„ ì´ìš©í• ì§€ ê³ ë¯¼ ì¤‘ì´ì‹œë¼ë©´, ì œê°€ ì¶”ì²œí•´ ë“œë¦´ê¹Œìš”?** (ì˜ˆ: ì‹ í•œì€í–‰, KBêµ­ë¦½ì€í–‰, í•˜ë‚˜ì€í–‰ ë“±)\n",
      "*   **ê³„ì¢Œ ê°œì„¤ ì‹œ í•„ìš”í•œ ì„œë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?** (ì˜ˆ: ì‹ ë¶„ì¦ ì‚¬ë³¸, ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸, ì„œë¥˜ ë“±)\n",
      "*   **ê³„ì¢Œ ê°œì„¤ ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì ì€ ë¬´ì—‡ì¸ê°€ìš”?** (ì˜ˆ: ì‹ ì²­ì„œ ì˜¤ë¥˜, ìŠ¹ì¸ ì§€ì—° ë“±)\n",
      "\n",
      "ì–´ë–¤ ë¶€ë¶„ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?  í˜¹ì‹œ íŠ¹ì • ì€í–‰ì„ ì—¼ë‘ì— ë‘ê³  ê³„ì‹ ê°€ìš”?  ë” ìì„¸í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´, ì œê°€ ë” ì •í™•í•˜ê²Œ ë‹µë³€í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "response = conversation.predict(\n",
    "    input=\"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•Œê² ìŠµë‹ˆë‹¤! ì´ì „ ë‹µë³€ì„ ë¶ˆë ›í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ë¹„ëŒ€ë©´ ì€í–‰ ê³„ì¢Œ ê°œì„¤ ê³¼ì • ìš”ì•½**\n",
      "\n",
      "1.  **ì€í–‰ ì„ íƒ:**\n",
      "    *   ì–´ë–¤ ì€í–‰ì„ ì´ìš©í• ì§€ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "    *   ê° ì€í–‰ì˜ íŠ¹ì§•ê³¼ ë¹„êµë¥¼ í•´ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "    *   ì˜ˆì‹œ: ì‹ í•œì€í–‰, KBêµ­ë¦½ì€í–‰, í•˜ë‚˜ì€í–‰ ë“±\n",
      "2.  **ì˜¨ë¼ì¸ ê³„ì¢Œ ê°œì„¤ ì‹ ì²­:**\n",
      "    *   ì›¹ì‚¬ì´íŠ¸ ë˜ëŠ” ì•±ì—ì„œ ì‹ ì²­í•©ë‹ˆë‹¤.\n",
      "    *   ì‹ ë¶„ì¦ ì‚¬ë³¸, ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸, ê³„ì¢Œ ê°œì„¤ ëª©ì  ì„œë¥˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "3.  **ê³„ì¢Œ ì¢…ë¥˜ ì„ íƒ:**\n",
      "    *   ì–´ë–¤ ì¢…ë¥˜ì˜ ê³„ì¢Œë¥¼ ê°œì„¤í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
      "    *   ì˜ˆ: ì¼ë°˜ ê³„ì¢Œ, ìë™ ì´ì²´ ê³„ì¢Œ, ëŒ€ì¶œ ê³„ì¢Œ ë“±\n",
      "4.  **ê³„ì¢Œ ì •ë³´ ì…ë ¥:**\n",
      "    *   ê³„ì¢Œ ì¢…ë¥˜ì— ë”°ë¼ í•„ìš”í•œ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "    *   ì˜ˆ: ê³„ì¢Œë²ˆí˜¸, ì˜ˆê¸ˆì, ê³„ì¢Œëª…, ê³„ì¢Œ ì¢…ë¥˜\n",
      "5.  **ê³„ì¢Œ ê°œì„¤ ì‹ ì²­ì„œ ì‘ì„±:**\n",
      "    *   ê³„ì¢Œ ê°œì„¤ ëª©ì ì„ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "6.  **ê³„ì¢Œ ê°œì„¤ ì‹ ì²­ì„œ ì‘ì„± ì™„ë£Œ:**\n",
      "    *   ì€í–‰ì—ì„œ ì‹ ì²­í•œ ê³„ì¢Œ ê°œì„¤ ì‹ ì²­ì„œë¥¼ í™•ì¸í•˜ê³  ìŠ¹ì¸ë°›ìŠµë‹ˆë‹¤.\n",
      "    *   ì´ë©”ì¼ ë˜ëŠ” ì•±ì„ í†µí•´ ì•ˆë‚´ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "7.  **ê³„ì¢Œ ê°œì„¤ ì™„ë£Œ:**\n",
      "    *   ê³„ì¢Œ ë²ˆí˜¸ì™€ ì˜ˆê¸ˆì ì •ë³´ë¥¼ í™•ì¸í•˜ì—¬ ê³„ì¢Œê°€ ê°œì„¤ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ì¶”ê°€ ì§ˆë¬¸**\n",
      "\n",
      "*   ì–´ë–¤ ì€í–‰ì„ ì´ìš©í• ì§€ ê³ ë¯¼ ì¤‘ì´ì‹œë¼ë©´, ì œê°€ ì¶”ì²œí•´ ë“œë¦´ê¹Œìš”? (ì˜ˆ: ì‹ í•œì€í–‰, KBêµ­ë¦½ì€í–‰, í•˜ë‚˜ì€í–‰ ë“±)\n",
      "*   ê³„ì¢Œ ê°œì„¤ ì‹œ í•„ìš”í•œ ì„œë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”? (ì˜ˆ: ì‹ ë¶„ì¦ ì‚¬ë³¸, ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸, ì„œë¥˜ ë“±)\n",
      "*   ê³„ì¢Œ ê°œì„¤ ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì ì€ ë¬´ì—‡ì¸ê°€ìš”? (ì˜ˆ: ì‹ ì²­ì„œ ì˜¤ë¥˜, ìŠ¹ì¸ ì§€ì—° ë“±)\n",
      "\n",
      "ì–´ë–¤ ë¶€ë¶„ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? í˜¹ì‹œ íŠ¹ì • ì€í–‰ì„ ì—¼ë‘ì— ë‘ê³  ê³„ì‹ ê°€ìš”? ë” ìì„¸í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´, ì œê°€ ë” ì •í™•í•˜ê²Œ ë‹µë³€í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# ì´ì „ ëŒ€í™”ë‚´ìš©ì„ ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ì •ë¦¬í•´ ë‹¬ë¼ëŠ” ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\n",
    "response = conversation.predict(\n",
    "    input=\"ì´ì „ ë‹µë³€ì„ ë¶ˆë ›í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationBufferWindowMemory ëŠ” ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ëŒ€í™”ì˜ ìƒí˜¸ì‘ìš© ëª©ë¡ì„ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë•Œ, ConversationBufferWindowMemory ëŠ” ëª¨ë“  ëŒ€í™”ë‚´ìš©ì„ í™œìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ìµœê·¼ Kê°œ ì˜ ìƒí˜¸ì‘ìš©ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŠ” ë²„í¼ê°€ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ê°€ì¥ ìµœê·¼ ìƒí˜¸ì‘ìš©ì˜ ìŠ¬ë¼ì´ë”© ì°½ì„ ìœ ì§€í•˜ëŠ” ë° ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4yvbq7s16359fdr947szsx5h0000gn/T/ipykernel_5553/2154617891.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ì€ ì´ì œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë³¸ì¸ ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì›í•˜ì‹œëŠ” ê³„ì¢Œ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆê¸ˆ ì¢…ë¥˜, í†µí™” ì¢…ë¥˜ ë“±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì •ë³´ë¥¼ ëª¨ë‘ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì…ë ¥í•´ ì£¼ì‹  ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ ì ˆì°¨ê°€ ê±°ì˜ ëë‚¬ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ìš© ì•½ê´€ì— ë™ì˜í•´ ì£¼ì‹œê³ , ê³„ì¢Œ ê°œì„¤ì„ ìµœì¢… í™•ì¸í•´ ì£¼ì„¸ìš”.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ëª¨ë“  ì ˆì°¨ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œê°€ ê°œì„¤ëœ ê±´ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë„¤, ê³„ì¢Œ ê°œì„¤ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ê³„ì¢Œ ë²ˆí˜¸ì™€ ê´€ë ¨ ì •ë³´ëŠ” ë“±ë¡í•˜ì‹  ì´ë©”ì¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤!\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ì •ë³´ë¥¼ ëª¨ë‘ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì…ë ¥í•´ ì£¼ì‹  ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ ì ˆì°¨ê°€ ê±°ì˜ ëë‚¬ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ìš© ì•½ê´€ì— ë™ì˜í•´ ì£¼ì‹œê³ , ê³„ì¢Œ ê°œì„¤ì„ ìµœì¢… í™•ì¸í•´ ì£¼ì„¸ìš”.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ëª¨ë“  ì ˆì°¨ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œê°€ ê°œì„¤ëœ ê±´ê°€ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ë„¤, ê³„ì¢Œ ê°œì„¤ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ê³„ì¢Œ ë²ˆí˜¸ì™€ ê´€ë ¨ ì •ë³´ëŠ” ë“±ë¡í•˜ì‹  ì´ë©”ì¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëŒ€í™” ê¸°ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationTokenBufferMemory ëŠ” ìµœê·¼ ëŒ€í™”ì˜ íˆìŠ¤í† ë¦¬ë¥¼ ë²„í¼ë¥¼ ë©”ëª¨ë¦¬ì— ë³´ê´€í•˜ê³ , ëŒ€í™”ì˜ ê°œìˆ˜ê°€ ì•„ë‹Œ í† í° ê¸¸ì´ ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë‚´ìš©ì„ í”ŒëŸ¬ì‹œ(flush)í•  ì‹œê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4yvbq7s16359fdr947szsx5h0000gn/T/ipykernel_5553/1847383367.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm, max_token_limit=150, return_messages=True  # ìµœëŒ€ í† í° ê¸¸ì´ë¥¼ 150ê°œë¡œ ì œí•œ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunoozzing/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ìµœê·¼ì— ì—¬ëŸ¬ë¶„ íšŒì‚¬ì˜ ê³µì‘ ê¸°ê³„ë¥¼ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤. ì„¤ì¹˜ ë°©ë²•ì„ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”! êµ¬ë§¤í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í•´ë‹¹ ê¸°ê³„ ëª¨ë¸ ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ë„¤, ëª¨ë¸ ë²ˆí˜¸ëŠ” XG-200ì…ë‹ˆë‹¤.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ê°ì‚¬í•©ë‹ˆë‹¤. XG-200 ëª¨ë¸ì˜ ì„¤ì¹˜ ì•ˆë‚´ë¥¼ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë¨¼ì €, ì„¤ì¹˜í•  ì¥ì†Œì˜ ì „ì› ê³µê¸‰ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. ê¸°ê³„ëŠ” 220V ì „ì›ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì „ì›ì€ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì¢‹ìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, ê¸°ê³„ë¥¼ í‰í‰í•˜ê³  ì•ˆì •ëœ ë°”ë‹¥ì— ë°°ì¹˜í•´ ì£¼ì„¸ìš”. ì´í›„, ì œê³µëœ ì‚¬ìš©ì ë§¤ë‰´ì–¼ì— ë”°ë¼ ì¼€ì´ë¸” ì—°ê²°ì„ ì§„í–‰í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì—°ê²°ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë§¤ë‰´ì–¼ì˜ 5í˜ì´ì§€ë¥¼ ì°¸ì¡°í•´ ì£¼ì„¸ìš”. ì¼€ì´ë¸” ì—°ê²°ì— ê´€í•œ ìƒì„¸í•œ ì§€ì¹¨ì´ ìˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ì–´ë ¤ì›€ì´ ìˆìœ¼ì‹œë©´ ì¶”ê°€ì ìœ¼ë¡œ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´, ì „ì›ì„ ì¼œê³  ì´ˆê¸° êµ¬ë™ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì ˆì°¨ëŠ” ë§¤ë‰´ì–¼ì˜ 10í˜ì´ì§€ì— ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ê¸°ê³„ì— ì´ìƒì´ ìˆê±°ë‚˜ ì¶”ê°€ì ì¸ ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ê°ì‚¬í•©ë‹ˆë‹¤, ë„ì›€ì´ ë§ì´ ë˜ì—ˆì–´ìš”!\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëŒ€í™”ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "memory.load_memory_variables({})[\"history\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationEntityMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì—”í‹°í‹° ë©”ëª¨ë¦¬ëŠ” ëŒ€í™”ì—ì„œ íŠ¹ì • ì—”í‹°í‹°ì— ëŒ€í•œ ì£¼ì–´ì§„ ì‚¬ì‹¤ì„ ê¸°ì–µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—”í‹°í‹° ë©”ëª¨ë¦¬ëŠ” ì—”í‹°í‹°ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ (LLM ì‚¬ìš©) ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ í•´ë‹¹ ì—”í‹°í‹°ì— ëŒ€í•œ ì§€ì‹ì„ ì¶•ì í•©ë‹ˆë‹¤(ì—­ì‹œ LLM ì‚¬ìš©)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n"
     ]
    }
   ],
   "source": [
    "# Entity Memoryë¥¼ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4yvbq7s16359fdr947szsx5h0000gn/T/ipykernel_5553/1756069824.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationEntityMemory(llm=llm),\n",
      "/Users/hyunoozzing/.pyenv/versions/3.11.11/envs/llm/lib/python3.11/site-packages/pydantic/main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "# ConversationChain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, I understand. It sounds like youâ€™re discussing two colleagues â€“ Hyunwoo and Lana â€“ who are planning to start their own company. Thatâ€™s a significant step, and itâ€™s good to hear about their plans.\\n\\nTo help me understand your request better and offer more relevant assistance, could you tell me what youâ€™d like to know or discuss about this situation? For example, are you interested in:\\n\\n*   **Their business idea?** (What kind of company are they planning to start?)\\n*   **Their challenges?** (What obstacles are they facing?)\\n*   **Their strategies?** (Whatâ€™s their plan for launching and growing the company?)\\n*   **Industry trends?** (Are there any relevant trends they should be aware of?)\\n*   **Something else entirely?**\\n\\nLet me know where youâ€™d like to start.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(\n",
    "    input=\"í˜„ìš°ì™€ ë¼ë‹ˆëŠ” í•œ íšŒì‚¬ì—ì„œ ì¼í•˜ëŠ” ë™ë£Œì…ë‹ˆë‹¤.\"\n",
    "    \"í˜„ìš°ëŠ” ê°œë°œìì´ê³  ë¼ë‹ˆëŠ” ë””ìì´ë„ˆì…ë‹ˆë‹¤. \"\n",
    "    \"ê·¸ë“¤ì€ ìµœê·¼ íšŒì‚¬ì—ì„œ ì¼í•˜ëŠ” ê²ƒì„ ê·¸ë§Œë‘ê³  ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'í˜„ìš°': 'í˜„ìš° is a developer and Lana is a designer, and they are planning to start their own company.',\n",
       " 'ë¼ë‹ˆ': 'ë¼ë‹ˆ is a designer colleague working with Hyunwoo, who is a developer and is planning to start their own company.',\n",
       " 'íšŒì‚¬': 'í˜„ìš°ëŠ” ê°œë°œìì´ê³  ë¼ë‹ˆëŠ” ë””ìì´ë„ˆì´ë©°, ê·¸ë“¤ì€ ìµœê·¼ íšŒì‚¬ì—ì„œ ì¼í•˜ëŠ” ê²ƒì„ ê·¸ë§Œë‘ê³  ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆìŠµë‹ˆë‹¤.',\n",
       " 'ê°œë°œì': 'Hyunwoo is a developer and Lana is a designer. They are planning to leave their current job and start their own company.',\n",
       " 'ë””ìì´ë„ˆ': 'í˜„ìš°ëŠ” ê°œë°œìì´ê³  ë¼ë‹ˆëŠ” ë””ìì´ë„ˆì…ë‹ˆë‹¤.',\n",
       " 'ì°¨ë¦´ ê³„íš': 'í˜„ìš°ì™€ ë¼ë‹ˆëŠ” ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆìŠµë‹ˆë‹¤.',\n",
       " 'ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼': 'í˜„ìš°ëŠ” ê°œë°œìì´ê³  ë¼ë‹ˆëŠ” ë””ìì´ë„ˆì´ë©°, ê·¸ë“¤ì€ ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆìŠµë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entity memory ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationKGMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì§€ì‹ ê·¸ë˜í”„ì˜ í˜ì„ í™œìš©í•˜ì—¬ ì •ë³´ë¥¼ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ì„œë¡œ ë‹¤ë¥¸ ê°œì²´ ê°„ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ê³ , ë³µì¡í•œ ì—°ê²°ë§ê³¼ ì—­ì‚¬ì  ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì‘í•˜ëŠ” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Ollama ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "llm = ChatOllama(model=\"gemma3:1b\")\n",
    "\n",
    "memory = ConversationKGMemory(llm=llm, return_messages=True)\n",
    "memory.save_context(\n",
    "    {\"input\": \"ì´ìª½ì€ Pangyo ì— ê±°ì£¼ì¤‘ì¸ ê¹€ì…œë¦¬ì”¨ ì…ë‹ˆë‹¤.\"},\n",
    "    {\"output\": \"ê¹€ì…œë¦¬ì”¨ëŠ” ëˆ„êµ¬ì‹œì£ ?\"},\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"ê¹€ì…œë¦¬ì”¨ëŠ” ìš°ë¦¬ íšŒì‚¬ì˜ ì‹ ì… ë””ìì´ë„ˆì…ë‹ˆë‹¤.\"},\n",
    "    {\"output\": \"ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤.\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"ê¹€ì…œë¦¬ì”¨ëŠ” ëˆ„êµ¬ì…ë‹ˆê¹Œ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
    "The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, prompt=prompt, memory=ConversationKGMemory(llm=llm)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, I understand. Letâ€™s begin.\\n\\nAI: Hi Teddy! Itâ€™s nice to meet you. Shirley is a new designer at your company, correct?  Iâ€™ve accessed information about her role and background.  Do you have any specific questions about her or your workplace?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.predict(\n",
    "    input=\"My name is Hyunwoo. rany is a coworker of mine, and she's a new designer at our company.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rany ì— ëŒ€í•œ ì§ˆë¬¸\n",
    "conversation_with_kg.memory.load_memory_variables({\"input\": \"who is rany?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
